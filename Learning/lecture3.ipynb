{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestrator-Workers Workflow\n",
    "# In this workflow, a central LLM dynamically breaks down tasks, delegates them to worker LLMs, and synthesizes their results.\n",
    "\n",
    "# When to use this workflow\n",
    "# This workflow is well-suited for complex tasks where you can't predict the subtasks needed. The key difference from simple parallelization is its flexibilityâ€”subtasks aren't pre-defined, but determined by the orchestrator based on the specific input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -angchain (c:\\users\\aditya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -angchain-community (c:\\users\\aditya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -angchain (c:\\users\\aditya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -angchain-community (c:\\users\\aditya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "DEPRECATION: uvicorn 0.14.0 has a non-standard dependency specifier click>=7.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of uvicorn or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's switch to python now for creating better systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=input(\"Enter the query on which you want to perform the task:\")\n",
    "\n",
    "orchestrator_prompt=f\"\"\"\n",
    "You are an manager of a company who needs to allocate tasks to workers.\n",
    "You are given a task: {n}\n",
    "You have 3 workers available.\n",
    "\n",
    "worker1 is a sentiment analysis expert.\n",
    "worker2 is a classification expert which can classify the text into technical,product,marketing,sales,finance,etc\n",
    "worker3 is a summarization expert.\n",
    "\n",
    "Return the output in the following format in XML format(strictly follow the format, nothing else should be outputed):\n",
    "\n",
    "<worker1>\n",
    "Actual Task: (Eg- \"Analyze the sentiment of the text\")\n",
    "</worker1>\n",
    "<worker2>\n",
    "Actual Task: (Eg- \"Classify the text into who should be assigned to this ticket from technical,product,marketing,sales,finance,etc\")\n",
    "</worker2>\n",
    "<worker3>\n",
    "Actual Task: (Eg- \"Summarize the text\")\n",
    "</worker3>\n",
    "\"\"\"\n",
    "\n",
    "def extract_worker1_task(text):\n",
    "    return text.split(\"worker1\")[1].split(\"</worker1>\")[0].strip()\n",
    "\n",
    "def extract_worker2_task(text):\n",
    "    return text.split(\"worker2\")[1].split(\"</worker2>\")[0].strip()\n",
    "\n",
    "def extract_worker3_task(text):\n",
    "    return text.split(\"worker3\")[1].split(\"</worker3>\")[0].strip()\n",
    "\n",
    "result=llm.invoke(orchestrator_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Task: Analyze the sentiment expressed in the bill-related text (\"my bill is very high\"). Determine if the sentiment is negative, positive, or neutral.\n"
     ]
    }
   ],
   "source": [
    "print(result.content.split('```')[1].split('<worker1>')[1].split(\"/worker1\")[0].split(\"<\")[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
