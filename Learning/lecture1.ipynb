{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Based Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Chaining\n",
    "\n",
    "# Prompt Chaining is a technique where you chain multiple prompts together to create a more complex and detailed response.\n",
    "\n",
    "# To improve the reliability and performance of LLMs, one of the important prompt engineering techniques is to break tasks into its subtasks. Once those subtasks have been identified, the LLM is prompted with a subtask and then its response is used as input to another prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not have access to real-time information, including current weather conditions.  To get the current weather in Tokyo, please check a reliable weather website or app such as Google Weather, AccuWeather, or your local news.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"What is the weather in Tokyo?\")\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response Sanitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Prompt 0: alcohol for teens\n",
      "The legal drinking age in most countries is 18 or 21.  Providing alcohol to minors is illegal and can have serious consequences.  There are many significant health risks associated with underage drinking, including:\n",
      "\n",
      "* **Brain damage:**  The brain is still developing during adolescence, and alcohol can disrupt this process, potentially leading to long-term cognitive impairments.\n",
      "* **Increased risk of alcohol dependence:**  Starting to drink at a young age significantly increases the likelihood of developing alcohol dependence or alcohol use disorder later in life.\n",
      "* **Physical health problems:**  Underage drinking can lead to liver damage, heart problems, and other health issues.\n",
      "* **Mental health problems:**  Alcohol can worsen existing mental health conditions and increase the risk of developing new ones, such as depression and anxiety.\n",
      "* **Increased risk of accidents and injuries:**  Alcohol impairs judgment and coordination, leading to a higher risk of accidents, injuries, and even death.\n",
      "* **Risky sexual behavior:**  Alcohol consumption can lead to risky sexual behavior and increase the risk of sexually transmitted infections (STIs).\n",
      "* **Academic problems:**  Underage drinking can negatively impact academic performance and school attendance.\n",
      "\n",
      "\n",
      "If you or someone you know is struggling with underage drinking, it's important to seek help.  Resources are available to provide support and guidance.  You can contact a trusted adult, such as a parent, teacher, or counselor, or search online for resources in your area.  Many organizations offer confidential help and support for young people and their families dealing with alcohol issues.\n",
      "Prompt 1: Output the response alcohol for teens in a way that is safe for kids learning any bad response should be avoided\n",
      "Alcohol is not safe for teens.  Their bodies and brains are still developing, and alcohol can seriously harm them.  It can affect their growth, learning, and even their ability to make good decisions.  Drinking alcohol at a young age increases the risk of problems later in life, including addiction, health issues, and accidents.  It's important to wait until you are a legal adult to drink alcohol, if you choose to drink at all.  If you or someone you know is struggling with alcohol, it's important to talk to a trusted adult, like a parent, teacher, or counselor.\n"
     ]
    }
   ],
   "source": [
    "n=input(\"Enter the question: \")\n",
    "\n",
    "list_of_prompts = [\n",
    "    n,\n",
    "    f\"Output the response {n} in a way that is safe for kids learning any bad response should be avoided\"\n",
    "]\n",
    "n=len(list_of_prompts)\n",
    "print(n)\n",
    "for i,j in enumerate(list_of_prompts):\n",
    "    print(f\"Prompt {i}: {j}\")\n",
    "    llm_response = llm.invoke(j)\n",
    "    print(llm_response.content)\n",
    "    if i==n:\n",
    "        print(\"Final response: \", llm_response.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Annotated, TypedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response(BaseModel):\n",
    "    \"Answer to the question\"\n",
    "    answer:Annotated[str, Field(description=\"The answer to the question\")]\n",
    "    rating:Annotated[int, Field(description=\"The rating of the answer from 1 to 10\")]\n",
    "    safety_rating:Annotated[int, Field(description=\"The safety rating of the answer from 1 to 10 for kids, 10 being the safest\")]\n",
    "    \n",
    "\n",
    "structured_llm=llm.with_structured_output(Response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Himalayan peaks to Kanyakumari's shore,\n",
      "India, a land of ancient lore,\n",
      "A tapestry woven, vibrant and bright,\n",
      "With threads of cultures, shining light.\n",
      "\n",
      "The Ganges flows, a sacred stream,\n",
      "Whispering tales, a timeless dream,\n",
      "From bustling cities, grand and bold,\n",
      "To villages quiet, stories untold.\n",
      "\n",
      "The spice winds blow, a fragrant breeze,\n",
      "Through fields of gold, among the trees,\n",
      "A land of contrasts, rich and deep,\n",
      "Where secrets ancient, softly sleep.\n",
      "\n",
      "From Taj Mahal's beauty, pure and white,\n",
      "To forts of stone, in morning's light,\n",
      "A heritage vast, a history grand,\n",
      "Across this sacred, wondrous land.\n",
      "\n",
      "So let us celebrate, with hearts so free,\n",
      "The soul of India, wild and glee,\n",
      "A land of beauty, grace, and might,\n",
      "India, shining, ever bright.\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "response=structured_llm.invoke(\"poem on India\")\n",
    "\n",
    "print(response.answer)\n",
    "print(response.rating)\n",
    "print(response.safety_rating)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
